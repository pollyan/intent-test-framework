"""
æµ‹è¯•æ€§èƒ½ä¼˜åŒ–é…ç½®
æä¾›æµ‹è¯•æ‰§è¡Œçš„æ€§èƒ½è°ƒä¼˜å’Œç›‘æ§åŠŸèƒ½
"""

import time
import functools
import threading
from typing import Dict, List, Any
from contextlib import contextmanager


class TestPerformanceMonitor:
    """æµ‹è¯•æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.test_times: Dict[str, float] = {}
        self.slow_tests: List[Dict[str, Any]] = []
        self.lock = threading.Lock()
        self.slow_test_threshold = 2.0  # 2ç§’
        self.very_slow_threshold = 5.0  # 5ç§’
    
    def record_test_time(self, test_name: str, duration: float):
        """è®°å½•æµ‹è¯•æ‰§è¡Œæ—¶é—´"""
        with self.lock:
            self.test_times[test_name] = duration
            
            if duration > self.slow_test_threshold:
                self.slow_tests.append({
                    'name': test_name,
                    'duration': duration,
                    'severity': 'very_slow' if duration > self.very_slow_threshold else 'slow'
                })
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        with self.lock:
            if not self.test_times:
                return {'total_tests': 0, 'avg_time': 0, 'slow_tests': []}
            
            total_time = sum(self.test_times.values())
            avg_time = total_time / len(self.test_times)
            
            return {
                'total_tests': len(self.test_times),
                'total_time': total_time,
                'avg_time': avg_time,
                'slow_tests': sorted(self.slow_tests, key=lambda x: x['duration'], reverse=True),
                'fastest_test': min(self.test_times.items(), key=lambda x: x[1]),
                'slowest_test': max(self.test_times.items(), key=lambda x: x[1])
            }
    
    @contextmanager
    def monitor_test(self, test_name: str):
        """æµ‹è¯•ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        start_time = time.time()
        try:
            yield
        finally:
            duration = time.time() - start_time
            self.record_test_time(test_name, duration)


# å…¨å±€æ€§èƒ½ç›‘æ§å®ä¾‹
performance_monitor = TestPerformanceMonitor()


def performance_test(threshold: float = 2.0):
    """æ€§èƒ½æµ‹è¯•è£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            test_name = f"{func.__module__}.{func.__qualname__}"
            
            with performance_monitor.monitor_test(test_name):
                result = func(*args, **kwargs)
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            duration = performance_monitor.test_times.get(test_name, 0)
            if duration > threshold:
                print(f"âš ï¸ æ…¢é€Ÿæµ‹è¯•è­¦å‘Š: {test_name} è€—æ—¶ {duration:.2f}s (é˜ˆå€¼: {threshold}s)")
            
            return result
        return wrapper
    return decorator


class DatabaseOptimizer:
    """æ•°æ®åº“æµ‹è¯•ä¼˜åŒ–å™¨"""
    
    @staticmethod
    def configure_sqlite_for_testing():
        """ä¸ºæµ‹è¯•ä¼˜åŒ–SQLiteé…ç½®"""
        from sqlalchemy import event
        from sqlalchemy.engine import Engine
        
        @event.listens_for(Engine, "connect")
        def set_sqlite_pragma(dbapi_connection, connection_record):
            if 'sqlite' in str(dbapi_connection):
                cursor = dbapi_connection.cursor()
                # æ€§èƒ½ä¼˜åŒ–é…ç½®
                cursor.execute("PRAGMA synchronous = OFF")  # å¼‚æ­¥å†™å…¥
                cursor.execute("PRAGMA journal_mode = MEMORY")  # å†…å­˜æ—¥å¿—
                cursor.execute("PRAGMA temp_store = MEMORY")  # å†…å­˜ä¸´æ—¶å­˜å‚¨
                cursor.execute("PRAGMA cache_size = -64000")  # 64MBç¼“å­˜
                cursor.execute("PRAGMA foreign_keys = ON")  # å¯ç”¨å¤–é”®
                cursor.close()
    
    @staticmethod
    def batch_insert_testdata(session, model_class, data_list):
        """æ‰¹é‡æ’å…¥æµ‹è¯•æ•°æ®"""
        if not data_list:
            return []
        
        # ä½¿ç”¨bulk_insert_mappingsæé«˜æ€§èƒ½
        session.bulk_insert_mappings(model_class, data_list)
        session.commit()
        return data_list


class APITestOptimizer:
    """APIæµ‹è¯•ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.request_cache = {}
        self.session_pool = []
    
    def cache_response(self, key: str, response_data: Any):
        """ç¼“å­˜APIå“åº”"""
        self.request_cache[key] = response_data
    
    def get_cached_response(self, key: str):
        """è·å–ç¼“å­˜çš„APIå“åº”"""
        return self.request_cache.get(key)
    
    @staticmethod
    def optimize_flask_test_client(app):
        """ä¼˜åŒ–Flaskæµ‹è¯•å®¢æˆ·ç«¯"""
        # ç¦ç”¨ä¸å¿…è¦çš„ä¸­é—´ä»¶
        app.config['TESTING'] = True
        app.config['WTF_CSRF_ENABLED'] = False
        app.config['LOGIN_DISABLED'] = True
        
        # ä¼˜åŒ–æ•°æ®åº“è¿æ¥
        app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
            'pool_pre_ping': True,
            'pool_recycle': 300,
            'pool_size': 5,
            'max_overflow': 10
        }
        
        return app


class ParallelTestManager:
    """å¹¶è¡Œæµ‹è¯•ç®¡ç†å™¨"""
    
    @staticmethod
    def get_optimal_worker_count():
        """è·å–æœ€ä¼˜çš„å·¥ä½œè¿›ç¨‹æ•°"""
        import os
        import multiprocessing
        
        cpu_count = multiprocessing.cpu_count()
        
        # è€ƒè™‘å†…å­˜é™åˆ¶
        available_memory_gb = 8  # å‡è®¾8GBå¯ç”¨å†…å­˜
        memory_per_worker = 0.5  # æ¯ä¸ªworkerå¤§çº¦éœ€è¦512MB
        
        max_workers_by_memory = int(available_memory_gb / memory_per_worker)
        
        # å–CPUæ•°é‡å’Œå†…å­˜é™åˆ¶çš„æœ€å°å€¼
        optimal_workers = min(cpu_count, max_workers_by_memory, 8)  # æœ€å¤š8ä¸ªworker
        
        return max(1, optimal_workers)
    
    @staticmethod
    def group_tests_by_speed(test_files):
        """æŒ‰æµ‹è¯•é€Ÿåº¦åˆ†ç»„æµ‹è¯•æ–‡ä»¶"""
        fast_tests = []
        slow_tests = []
        
        # è¿™é‡Œå¯ä»¥åŸºäºå†å²æ•°æ®æˆ–æ–‡ä»¶å¤§å°æ¥åˆ†ç±»
        for test_file in test_files:
            if 'error_scenarios' in test_file or 'integration' in test_file:
                slow_tests.append(test_file)
            else:
                fast_tests.append(test_file)
        
        return fast_tests, slow_tests


class TestResourceManager:
    """æµ‹è¯•èµ„æºç®¡ç†å™¨"""
    
    def __init__(self):
        self.resource_pool = {}
        self.cleanup_callbacks = []
    
    def register_resource(self, name: str, resource: Any):
        """æ³¨å†Œæµ‹è¯•èµ„æº"""
        self.resource_pool[name] = resource
    
    def get_resource(self, name: str):
        """è·å–æµ‹è¯•èµ„æº"""
        return self.resource_pool.get(name)
    
    def register_cleanup(self, callback):
        """æ³¨å†Œæ¸…ç†å›è°ƒ"""
        self.cleanup_callbacks.append(callback)
    
    def cleanup_all(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        for callback in reversed(self.cleanup_callbacks):
            try:
                callback()
            except Exception as e:
                print(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")
        
        self.resource_pool.clear()
        self.cleanup_callbacks.clear()


# å…¨å±€èµ„æºç®¡ç†å™¨
resource_manager = TestResourceManager()


def setup_test_performance_monitoring():
    """è®¾ç½®æµ‹è¯•æ€§èƒ½ç›‘æ§"""
    import pytest
    import atexit
    
    def print_performance_report():
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        report = performance_monitor.get_performance_report()
        if report['total_tests'] > 0:
            print("\n" + "="*60)
            print("ğŸ“Š æµ‹è¯•æ€§èƒ½æŠ¥å‘Š")
            print("="*60)
            print(f"æ€»æµ‹è¯•æ•°é‡: {report['total_tests']}")
            print(f"æ€»æ‰§è¡Œæ—¶é—´: {report['total_time']:.2f}s")
            print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {report['avg_time']:.2f}s")
            
            if report['slow_tests']:
                print(f"\nâš ï¸ æ…¢é€Ÿæµ‹è¯• ({len(report['slow_tests'])} ä¸ª):")
                for test in report['slow_tests'][:5]:  # æ˜¾ç¤ºå‰5ä¸ªæœ€æ…¢çš„
                    severity_icon = "ğŸŒ" if test['severity'] == 'very_slow' else "â°"
                    print(f"  {severity_icon} {test['name']}: {test['duration']:.2f}s")
            
            fastest_name, fastest_time = report['fastest_test']
            slowest_name, slowest_time = report['slowest_test']
            print(f"\nâš¡ æœ€å¿«æµ‹è¯•: {fastest_name} ({fastest_time:.2f}s)")
            print(f"ğŸŒ æœ€æ…¢æµ‹è¯•: {slowest_name} ({slowest_time:.2f}s)")
    
    # æ³¨å†Œé€€å‡ºæ—¶æ‰“å°æŠ¥å‘Š
    atexit.register(print_performance_report)


def pytest_configure():
    """Pytesté…ç½®é’©å­"""
    setup_test_performance_monitoring()
    DatabaseOptimizer.configure_sqlite_for_testing()


def pytest_collection_modifyitems(config, items):
    """ä¿®æ”¹æµ‹è¯•æ”¶é›†ï¼Œä¼˜åŒ–æ‰§è¡Œé¡ºåº"""
    # æŒ‰æµ‹è¯•ç±»å‹æ’åºï¼šå¿«é€Ÿæµ‹è¯•ä¼˜å…ˆ
    def sort_key(item):
        # æ£€æŸ¥æ ‡è®°
        if item.get_closest_marker('fast'):
            return 0
        elif item.get_closest_marker('slow'):
            return 2
        else:
            return 1
    
    items.sort(key=sort_key)


# æµ‹è¯•é…ç½®ç±»
class TestConfig:
    """æµ‹è¯•é…ç½®"""
    
    # æ€§èƒ½é˜ˆå€¼
    SLOW_TEST_THRESHOLD = 2.0  # 2ç§’
    VERY_SLOW_TEST_THRESHOLD = 5.0  # 5ç§’
    
    # æ•°æ®åº“é…ç½®
    TEST_DATABASE_URI = 'sqlite:///:memory:'
    DATABASE_POOL_SIZE = 5
    DATABASE_MAX_OVERFLOW = 10
    
    # APIæµ‹è¯•é…ç½®
    API_TIMEOUT = 5.0  # 5ç§’è¶…æ—¶
    MAX_CONCURRENT_REQUESTS = 10
    
    # èµ„æºé™åˆ¶
    MAX_MEMORY_MB = 512  # æ¯ä¸ªæµ‹è¯•è¿›ç¨‹æœ€å¤§å†…å­˜
    MAX_TEST_DURATION = 30  # 30ç§’æœ€å¤§æµ‹è¯•æ—¶é•¿
    
    # Mocké…ç½®
    ENABLE_EXTERNAL_API_MOCKS = True
    MOCK_RESPONSE_DELAY = 0.1  # 100msæ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ